%
% File graph_system.tex
%

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2017}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{breqn}
\usepackage{pgfplotstable}
\usepackage{algorithm2e}
\usepackage{hhline}
\usepackage{multirow}
\usepackage[font=small]{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{float}
\usepackage{lipsum,adjustbox}
\usepackage{tikz}
\usepackage{tikz-dependency}
\usepackage{enumitem}
\usepackage{xr}
\externaldocument{acl2017_supp}
\usetikzlibrary{shapes,fit,calc,er,positioning,intersections,decorations.shapes,mindmap,trees}
\tikzset{decorate sep/.style 2 args={decorate,decoration={shape backgrounds,shape=circle,
      shape size=#1,shape sep=#2}}}
\newcommand{\oa}[1]{\footnote{\color{red} #1}}
\newcommand{\daniel}[1]{\footnote{\color{blue} #1}}
\newcommand{\com}[1]{}
\newcommand{\parser}[1]{TUPA\textsubscript{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\SetKwRepeat{Do}{do}{while}

\hyphenation{SemEval}
\hyphenation{PARSEVAL}
\hyphenation{DAGParser}
\hyphenation{TurboSemanticParser}
\hyphenation{MaltParser}

\def\linkspace#1#2{\leavevmode
\def\tmp##1{\nolinebreak[2]\href{#1}{\hbox{##1}}}%
\xlinkspace#2 \relax}

\def\xlinkspace#1 #2{%
 \ifx\relax#2%
 \xlinkdash#1-\relax
 \else
 \xlinkdash#1 -\relax
 \expandafter\xlinkspace\expandafter#2%
 \fi}

\def\xlinkdash#1-#2{%
 \ifx\relax#2%
 \tmp{#1}%
 \else
 \tmp{#1-}%
 \expandafter\xlinkdash\expandafter#2%
 \fi}

%\aclfinalcopy % Uncomment this line for the final submission
\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{A Complete and Sound Transition System for Graph Parsing}

\author{Daniel Hershcovich$^{1,2}$ \\
  $^1$The Edmond and Lily Safra Center for Brain Sciences \\
  $^2$School of Computer Science and Engineering \\
  Hebrew University of Jerusalem \\
  \texttt{danielh@cs.huji.ac.il}
}

\date{}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%     Abstract     %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Transition systems have been proposed for many tasks in NLP.
We present a general transition system that is complete and sound with respect to DAG parsing,
and verify experimentally that it is suitable for many different representation schemes.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}

Transition-based parsing is a widely used framework for natural language parsing.
Transition-based parsers scan the text from start to end,
and create the parse incrementally by applying a \textit{transition}
at each step to the parser's state,
defined using three data structures: a buffer $B$ of tokens and nodes to be processed,
a stack $S$ of nodes currently being processed,
and a graph $G=(V,E,\ell)$ of constructed nodes and edges,
where $V$ is the set of \emph{nodes}, $E$ is the set of \emph{edges},
and $\ell : E \to L$ is the \emph{label} function, $L$ being the set of possible labels.
Some states are marked as \textit{terminal}, meaning that $G$ is the final output.
A classifier is used at each step to select the next transition based on features
encoding the parser's current state.
During training, an oracle creates training instances for the classifier,
based on gold-standard annotations.

Many variations to this model have been proposed, such as using more than one stack to support
non-projective dependency parsing \cite{gomez2010a},
as well as easy-first parsing rather than following the order of tokens \cite{goldberg2010efficient}.

A \textit{transition system} \cite{Nivr:06,nivre2008algorithms} may in general be used to cast structure prediction
problems as sequence prediction problems.
The framework has been applied successfully to many NLP tasks
\cite[][among others]{lample-EtAl:2016:N16-1,kiperwasser2016simple,zhang-zhang-fu:2016:P16-1,kong2017dragnn,hershcovich2017a}.

Broad coverage of graph structures is important for 

We present a general transition system for DAG parsing,
and verify experimentally that it is capable of parsing many different representation
schemes.\footnote{Our code will be made freely available upon publication.}

The rest of the paper is structured as follows:
\secref{sec:system} describes our transition system.
\secref{sec:completeness} proves our transition system is complete with respect to anchored DAGs, and
\secref{sec:soundness} proves it is sound.
\secref{sec:related_work} summarizes related work, and
\secref{sec:conclusion} concludes the paper.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Transition System}\label{sec:system}

Given a sequence of tokens $w_1, \ldots, w_n$, we predict a UCCA graph $G$ over the sequence.
Parsing starts with a single node on the stack (an artificial root node), and the input tokens
in the buffer. \figref{fig:transitions} shows the transition set.

\paragraph{Transition set.}
In addition to the standard \textsc{Shift} and \textsc{Reduce} operations, 
we follow previous work in transition-based constituency parsing \cite{sagae2005classifier},
adding the \textsc{Node} transition for creating new non-terminal nodes.
For every $X\in L$,
\textsc{Node$_X$} creates a new node on the buffer as a parent of the first element on the stack, with an $X$-labeled edge.

\textsc{Left-Edge$_X$} and \textsc{Right-Edge$_X$} create a new primary $X$-labeled edge between the first two elements on the stack, where the parent is the left or the right node, respectively.
As a UCCA node may only have one incoming primary edge,
\textsc{Edge} transitions are disallowed if the child node already
has an incoming primary edge.

\textsc{Left-Remote$_X$} and \textsc{Right-Remote$_X$} do not have this restriction,
and the created edge is additionally marked as \textit{remote}.
We distinguish between these two pairs of transitions to allow the parser to create remote edges
without the possibility of producing invalid graphs.
To support the prediction of multiple parents, node and edge transitions
leave the stack unchanged, as in other work on
transition-based dependency graph parsing
\cite{sagae2008shift,ribeyre-villemontedelaclergerie-seddah:2014:SemEval,tokgoz2015transition}.

\textsc{Reduce} pops the stack, to allow removing a node
once all its edges have been created.

To handle discontinuous nodes, \textsc{Swap} pops the second
node on the stack and adds it to the top of the buffer, as with the similarly
named transition in previous work \cite{nivre2009non,maier2015discontinuous}.
This transition uses the notion of a \textit{swap index}:
intuitively, this index reflects the "natural order" of nodes,
according to the order of terminals in the text and the terminal descendants of non-terminal nodes.
The root's swap index is 0, and for each terminal, its swap index is its position in the text
(starting for 1 for the first terminal).
Whenever a non-terminal node is created, its swap index is the arithmetic mean between
the swap indices of the top of the stack ($s_0$) and the first element in the buffer ($b_0$).
This is appropriate, since for any node-creating transition, the new node is created
as the first element on the buffer, i.e., in between $s_0$ and the current $b_0$.


Finally, \textsc{Finish} pops the root node and marks the state as terminal.

\begin{figure*}
	\begin{adjustbox}{width=\textwidth,margin=3pt,frame}
	\begin{tabular}{llll|l|llllc|c}
		\multicolumn{4}{c|}{\textbf{\small Before Transition}} & \textbf{\small Transition} & \multicolumn{5}{c|}{\textbf{\small After Transition}} & \textbf{\small Condition} \\
		\textbf{\footnotesize Stack} & \textbf{\footnotesize Buffer} & \textbf{\footnotesize Nodes} & \textbf{\footnotesize Edges} & & \textbf{\footnotesize Stack} & \textbf{\footnotesize Buffer} & \textbf{\footnotesize Nodes} & \textbf{\footnotesize Edges} & \textbf{\footnotesize Terminal?} & \\
		$S$ & $x \;|\; B$ & $V$ & $E$ & \textsc{Shift} & $S \;|\; x$ & $B$ & $V$ & $E$ & $-$ & \\
		$S \;|\; x$ & $B$ & $V$ & $E$ & \textsc{Reduce} & $S$ & $B$ & $V$ & $E$ & $-$ & \\
		$S \;|\; x$ & $B$ & $V$ & $E$ & \textsc{Node$_X$} & $S \;|\; x$ & $y \;|\; B$ & $V \cup \{ y \}$ & $E \cup \{ (y,x)_X \}$ & $-$ &
		$x \neq \mathrm{root}$ \\
		$S \;|\; y,x$ & $B$ & $V$ & $E$ & \textsc{Left-Edge$_X$} & $S \;|\; y,x$ & $B$ & $V$ & $E \cup \{ (x,y)_X \}$ & $-$ &
		\multirow{4}{50pt}{\vspace{-5mm}\[\left\{\begin{array}{l}
		x \not\in w_{1:n},\\
		y \neq \mathrm{root},\\
		y \not\leadsto_G x
		\end{array}\right.\]} \\
		$S \;|\; x,y$ & $B$ & $V$ & $E$ & \textsc{Right-Edge$_X$} & $S \;|\; x,y$ & $B$ & $V$ & $E \cup \{ (x,y)_X \}$ & $-$ & \\
		$S \;|\; y,x$ & $B$ & $V$ & $E$ & \textsc{Left-Remote$_X$} & $S \;|\; y,x$ & $B$ & $V$ & $E \cup \{ (x,y)_X^* \}$ & $-$ & \\
		$S \;|\; x,y$ & $B$ & $V$ & $E$ & \textsc{Right-Remote$_X$} & $S \;|\; x,y$ & $B$ & $V$ & $E \cup \{ (x,y)_X^* \}$ & $-$ & \\
		$S \;|\; x,y$ & $B$ & $V$ & $E$ & \textsc{Swap} & $S \;|\; y$ & $x \;|\; B$ & $V$ & $E$ & $-$ &
		$\mathrm{i}(x) < \mathrm{i}(y)$ \\
		$[\mathrm{root}]$ & $\emptyset$ & $V$ & $E$ & \textsc{Finish} & $\emptyset$ & $\emptyset$ & $V$ & $E$ & $+$ & \\
	\end{tabular}
	\end{adjustbox}
	\caption{\label{fig:transitions}
	  Transition set for DAG parsing.
	  We write the stack with its top to the right and the buffer with its head to the left.
	  $(\cdot,\cdot)_X$ denotes a primary $X$-labeled edge, and $(\cdot,\cdot)_X^*$ a remote $X$-labeled edge.
	  $\mathrm{i}(x)$ is a running index for the created nodes.
	  In addition to the specified conditions,
	  the prospective child in an \textsc{Edge} transition must not already have a primary parent.
	}
\end{figure*}

\paragraph{Oracle.}
For training the transition classifiers, we use a dynamic oracle \cite{goldberg2012dynamic},
i.e., an oracle that outputs a set of optimal transitions: when
applied to the current parser state, the gold
standard graph is reachable from the resulting state.
For example, the oracle would predict a \textsc{Node} transition if the stack 
has on its top a parent in the gold graph that has not been created,
but would predict a \textsc{Right-Edge} transition if the second stack
element is a parent of the
first element according to the gold graph and the edge between them has not been created.
The transition predicted by the classifier is deemed correct
and is applied to the parser state to reach the subsequent state,
if the transition is included in the set of optimal transitions.
Otherwise, a random optimal transition is applied,
and for the perceptron-based parser, the classifier's weights are updated according
to the perceptron update rule.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Completeness}\label{sec:completeness}

Here we sketch a proof for the fact that the transition set defined in \cite{hershcovich2017a}
is capable of producing any rooted, labeled, anchored DAG.
This proves that the transition set is complete with respect to the class of graphs that
comprise UCCA.

Let $G=(V,E,\ell)$ be a graph with labels $\ell:E\rightarrow L$
over a sequence of tokens $w_1, \ldots, w_n$.
Parsing starts with $w_1, \ldots, w_n$ on the buffer,
and the root node on the stack.

First we show that every node can be created, by induction on the node height:
every terminal (height zero) already exists at the beginning of the parse
(and so does the root node).
Let $v\in V$ be of height $k$, and assume all nodes of height less than $k$ can be created.
Take any (primary) child $u$ of $v$: its height must be less than $k$.
If $u$ is a terminal, apply \textsc{Shift} until it lies at the head of the buffer.
Otherwise, by our assumption, $u$ can still be created.
Right after $u$ is created, it lies at the head of the buffer.
A \textsc{Shift} transition followed by a \textsc{Node}$_{\ell(v,u)}$ transition will
move $u$ to the stack and create $v$ on the buffer, with the correct edge label.

Next, we show that every edge can be created.
Let $(v,u) \in E$ be any edge with parent $v$ and child $u$.
Assume $v$ and $u$ have both been created (we already showed that both are created eventually).
If either $v$ or $u$ are in the buffer, apply \textsc{Shift} until both are in the stack.
If both are in the stack but neither is at the stack top, apply \textsc{Swap} transitions
until either moves to the buffer, and then apply \textsc{Shift}.
Now, assume either $v$ or $u$ is at the stack top.
If the other is not the second element on the stack, apply \textsc{Swap} transitions until it is.
Finally, $v$ and $u$ are the top two elements on the stack.
If they are in that order, apply \textsc{Right-Edge}$_{\ell(v,u)}$
(or \textsc{Right-Remote}$_{\ell(v,u)}$ if the edge between them is remote).
Otherwise, apply \textsc{Left-Edge}$_{\ell(v,u)}$
(or \textsc{Left-Remote}$_{\ell(v,u)}$ if the edge between them is remote).
This creates $(v,u)$ with the correct edge label.

Once all nodes and edges have been created, we can apply \textsc{Reduce} until only the
root node remains on the stack, and then \textsc{Finish}.
This yields exactly the graph $G$.

Note that the distinction we made between primary and remote transitions is suitable for UCCA parsing.
For general graph parsing without this distinction,
the \textsc{Remote} transitions can be removed, as well as the single-primary-parent
restriction on \textsc{Edge} transition.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Soundness}\label{sec:soundness}

We now turn to prove the fact that every transition sequence allowed by our transition system
indeed corresponds to a valid anchored DAG.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}\label{sec:related_work}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{sec:conclusion}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section*{Acknowledgments}
%
%This work was supported by the HUJI Cyber Security Research Center
%in conjunction with the Israel National Cyber Bureau in the Prime Minister's Office,
%and by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI).
%The first author was supported by a fellowship from the
%Edmond and Lily Safra Center for Brain Sciences.
%We thank Wolfgang Maier, Nathan Schneider, Elior Sulem
%and the anonymous reviewers for their helpful comments.


\bibliography{references}
\bibliographystyle{acl_natbib}

\end{document}

