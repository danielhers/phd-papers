
%
% File divergences.tex


\documentclass[11pt,a4paper,table]{article}
%\usepackage[draft]{hyperref}  % removing this line sometimes causes errors, but we should remove it still
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

\aclfinalcopy % Uncomment this line for the final submission
\def\aclpaperid{287} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{tikz-dependency}
\usepackage[warn]{textcomp}
\usepackage[font=small]{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{etoolbox}
\usepackage{xr}
\usepackage{xfrac}
\usepackage{pgf}
\usepackage{collcell}
\usepackage{booktabs}
%\usepackage{listings}

\makeatletter
\renewcommand{\@BIBLABEL}{\@emptybiblabel}
\newcommand{\@emptybiblabel}[1]{}
\makeatother
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\com}[1]{}
\newcommand{\oa}[1]{\footnote{\color{red}OA: #1}}
\newcommand{\daniel}[1]{\footnote{\color{blue}DH: #1}}

\hyphenation{SemEval}
\hyphenation{English}
\hyphenation{PredPatt}
\setlength{\belowcaptionskip}{-10pt}


\usetikzlibrary{shapes,shapes.misc}


% for confusion matrix
\newcommand{\ApplyGradient}[1]{%
  \pgfmathsetmacro{\PercentColor}{(#1-0)/14.02}%
  \pgfmathsetmacro{\PercentInverse}{ifthenelse(\PercentColor > 70, 0, 100)}%
  %\textcolor{black!\PercentColor}{#1}
  \edef\x{\noexpand\cellcolor{red!\PercentColor}}\x\textcolor{black!\PercentInverse}{#1}%
}
\newcolumntype{R}{>{\collectcell\ApplyGradient}{c}<{\endcollectcell}}


\title{Content Differences in Syntactic and Semantic Representations}

\author{Daniel Hershcovich$^{1,2}$ \\
  \\\And
  Omri Abend$^2$ \\
  $^1$The Edmond and Lily Safra Center for Brain Sciences \\
  $^2$School of Computer Science and Engineering \\
  Hebrew University of Jerusalem \\
  \texttt{\{danielh,oabend,arir\}@cs.huji.ac.il}
  \\\And
  Ari Rappoport$^2$
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
  %1. performance gains of syntax for semantics
  %2. but, an ongoing debate
  %3. the development of "better" methods is hindered by lack of studies
  %4. we address the gap

  Syntactic analysis plays an important role in semantic parsing,
  but this role remains a topic of ongoing debate.
  The debate has been constrained by the scarcity of empirical comparative studies between syntactic and semantic schemes,
  which hinders the development of parsing methods informed by the details of target schemes and constructions.
%  as demonstrated by methods such as multi-task learning and syntactic features.
%  However, the scarcity of empirical comparative studies between syntactic and semantic schemes
  %results in existing methods being almost invariably generic,
  %  This is partly due to 
  We target this gap, and take Universal Dependencies (UD) and UCCA as a test case.
  %We emprically evaluate in what cases the two schemes converge and diverge in their content,
  After abstracting away from differences of convention or formalism,
  we find that most content divergences can be ascribed to: 
  (1) UCCA's distinction between a Scene and a non-Scene; % as opposed to UD's POS-based distinctions;
  (2) UCCA's distinction between primary relations, secondary ones and participants; %, not accounted for by UD; 
  (3) different treatment of multi-word expressions, and
  (4) different treatment of inter-clause linkage.
  We further discuss the long tail of cases where the two schemes take markedly
  different approaches.
  Finally, we show that the proposed comparison methodology can be used
  for fine-grained evaluation of UCCA parsing,
  highlighting both challenges and potential sources for improvement.
  The substantial differences between the schemes suggest that
  semantic parsers are likely to benefit downstream text understanding applications
  beyond their syntactic counterparts.
\end{abstract}


\section{Introduction}\label{sec:introduction}
  
  Semantic representations hold promise due to
  their ability to transparently reflect distinctions relevant for text understanding
  applications. For example, syntactic representations
  are usually sensitive to distinctions based on POS (part of speech), such as between compounds
  and possessives. Semantic schemes are  less likely to make
  this distinction since a possessive can often be paraphrased as a compound
  and vice versa (e.g., ``US president''/``president of the US''),
  but may distinguish different senses of possessives (e.g., ``some of the presidents'' and ``inauguration of the presidents'').
%  where a syntactic scheme would not.

  Nevertheless, little empirical study has been done on what distinguishes semantic schemes from
  syntactic ones, which are still in many cases the backbone of text understanding systems. 
  Such studies are essential for 
  (1) determining whether and to what extent semantic methods should be adopted for text understanding applications;
  (2) defining better inductive biases for semantic parsers, and allowing better use of information encoded in syntax;
  (3) pointing at semantic distinctions unlikely to be resolved by syntax.

  The importance of such an empirical study is emphasized by the ongoing discussion as to what role syntax should
  play in semantic parsing, if any \cite{swayamdipta2018syntactic,strubell2018linguistically,P18-1192,C18-1233}.
  See \S\ref{sec:related_work}.

  This paper aims to address this gap,
  focusing on {\it content} differences.
  As a test case, we compare relatively similar schemes (\S\ref{sec:representations}):
  the syntactic Universal Dependencies \cite[UD; ][]{nivre2016universal},
  and the semantic Universal Conceptual Cognitive Annotation \cite[UCCA; ][]{abend2013universal}.
  
  We annotate 804 UD-annotated sentences with UCCA (\S\ref{sec:shared}),
  and develop a converter to assimilate UD and UCCA,
  as they use formally different graph structures
  (\S\ref{sec:methodology}).
  We then align their nodes, and identify which UCCA categories match which UD relations,
  and which are unmatched.

  Most content differences are due to (\S\ref{sec:analysis}):
  \begin{enumerate}[itemsep=0.159mm,leftmargin=5.95mm]
      \item UCCA's distinction between words and phrases that evoke Scenes (events) and ones that do not.
        For example, eventive and non-eventive nouns are treated differently in UCCA, but similarly in UD.
        %THis distinction that cuts across grammatical categories
        %as opposed to UD's POS-based distinction (predicates, nominals). % (\S\ref{sec:s}).
      \item UCCA's distinction between primary relations, secondary relations
        and Participants, in contrast to UD's core/non-core distinction. % (\S\ref{sec:arguments}).
      \item Different treatment of multi-word expressions (MWEs),
        where UCCA has a stronger tendency to explicitly mark them. % (\S\ref{sec:mwe}).
      \item UCCA's conflation of several syntactic realizations of inter-clause linkage,
        and disambiguation of other cases that UD treats similarly.
        % (e.g., infinitive vs. purposive \textit{to}). % (\S\ref{sec:linkage}).
   \end{enumerate}

  We show that the differences between the schemes are substantial, and suggest that
  UCCA parsing in particular and semantic parsing in general are likely to benefit
  downstream text understanding applications.
  For example, only 73\% of arguments are shared between UCCA and UD,
  i.e., many semantic participants cannot be recovered from UD.\footnote{This excludes cases of shared 
  argumenthood, which are partially covered by \textit{enhanced UD}. See \S\ref{sec:conversion}.}
  Our findings are relevant to other semantic representations, given their 
  significant overlap in content \cite{abend2017state}.
    
  %   Other divergences stem from a different treatment of coordination, apposition and copulas.% (\S\ref{sec:misc}).
  
  A methodology for comparing syntactic and semantic treebanks can also support fine-grained error 
  analysis of semantic parsers, as illustrated by \citet{szubert2018structured} 
  for AMR \citep{banarescu2013abstract}.
  To demonstrate the utility of our comparison methodology,
  we perform fine-grained error analysis on UCCA parsing,
  according to UD relations (\S\ref{sec:fine_grained}).
  Results highlight challenges for current parsing technology,
  and expose cases where UCCA parsers may benefit from modeling syntactic structure more directly.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Representations}\label{sec:representations}

  The conceptual and formal similarity between UD and UCCA can be traced back
  to their shared design principles:
  both are designed to be applicable across languages and domains, 
  to enable rapid annotation and to support text understanding
  applications. This section provides a brief introduction to each of the schemes, whereas
  the next sections discuss their content in further
  detail.\footnote{See Supplementary Material for a definition of each category in both schemes,
  and their abbreviations.}
  


\paragraph{UCCA}\label{sec:ucca}
%  \citep[Universal Cognitive Conceptual Annotation;][]{abend2013universal} is a
  is a semantic annotation scheme rooted in typological 
  and cognitive linguistic theory.
  It aims to represent the main semantic phenomena in text, abstracting away from syntactic forms.
  Shown to be preserved remarkably well across translations \citep{sulem2015conceptual}, it has been applied to
  improve text simplification \citep{sulem2018simple},
  and text-to-text generation evaluation \citep{birch2016hume,choshen2018usim,sulem2018samsa}.

  Formally, UCCA structures are directed acyclic graphs (DAGs) whose nodes (or {\it units}) correspond either to words,
  or to elements viewed as a single entity according to some semantic or cognitive consideration.
  Edges are labeled, indicating the role of a child in the relation the parent represents.
  A {\it Scene} is UCCA's notion of an event or a frame, and is a description of a movement, an action or a state which persists in time. 
  Every Scene contains one primary relation, which can be either a Process or a State. 
  Scenes may contain any number of Participants, a category which also includes abstract participants and locations.
  They may also contain temporal relations (Time), and secondary relations (Adverbials), 
  which cover semantic distinctions such as manner, modality and aspect.\footnote{Despite the
  similar terminology, UCCA Adverbials are not necessarily adverbs syntactically.}

  Scenes may be \textit{linked} to one another in several ways.
  First, a Scene can provide information about some entity,
  in which case it is marked as an Elaborator.
  This often occurs in the case of participles or relative clauses.
  For example, ``(child) who went to school'' is an Elaborator Scene
  in ``The child who went to school is John''.
  A Scene may also be a Participant in another Scene. For example, ``John went to school'' in the sentence: ``He said John went to school''. 
  In other cases, Scenes are annotated as Parallel Scenes (H), which are flat structures and may include a Linker (L), 
  as in: ``When$_L$ [he arrives]$_H$, [he will call them]$_H$''.

  Non-Scene units are headed by units of the category Center,
  denoting the type of entity or thing described by the whole unit.
  Elements in non-Scene units include Quantifiers (such as ``{\it dozens} of people'') and
  Connectors (mostly coordinating conjunctions).
  Other modifiers to the Center are marked as Elaborators.
  
%  Relators correspond in English mostly to preposition
  
  UCCA distinguishes \textit{primary} edges, corresponding 
  to explicit relations, from \textit{remote} edges,
  which allow for a unit to participate
  in several super-ordinate relations.
  See example in Figure~\ref{fig:example_ucca}.
  Primary edges form a tree, whereas remote edges (dashed) enable reentrancy, forming a DAG.
  %Table~\ref{} gives a short description of each UCCA category.  % supp. material (footnote above)

\begin{figure}[th]
  \centering
  \scalebox{.8}{
    \begin{tikzpicture}[level distance=9mm, sibling distance=19mm, ->,
        every circle node/.append style={fill=black}]
      \tikzstyle{word} = [font=\rmfamily,color=black]
      \node (ROOT) [circle] {}
        child {node (After) [word] {After} edge from parent node[above] {\scriptsize $L$}}
        child {node (graduation) [circle] {}
        {
          child {node [word] {graduation} edge from parent node[left] {\scriptsize $P$}}
        } edge from parent node[right] {\scriptsize $H$} }
        child {node [word] {,} edge from parent node[below] {\scriptsize $U$}}
        child {node (moved) [circle] {}
        {
          child {node (John) [word] {John} edge from parent node[left] {\scriptsize $A$}}
          child {node [word] {moved} edge from parent node[left] {\scriptsize $P$}}
          child {node [circle] {}
          {
            child {node [word] {to} edge from parent node[left] {\scriptsize $R$}}
            child {node [word] {Paris} edge from parent node[right] {\scriptsize $C$}}
          } edge from parent node[above] {\scriptsize $A$} }
        } edge from parent node[right] {\scriptsize $H$} }
        ;
      \draw[dashed,->] (graduation) to node [above] {\scriptsize $A$} (John);
    \end{tikzpicture}
    }
\caption{\label{fig:example_ucca}
 Example UCCA graph. Dashed: a remote edge.}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{UD}\label{sec:ud}
%\cite[UD; ][]{nivre2016universal} is
is a syntactic dependency scheme used in many languages,
aiming for cross-linguistically consistent and coarse-grained treebank
annotation. Formally, UD uses bi-lexical trees, with edge labels 
representing syntactic relations.
Being a dependency representation, UD is thus underspecified:
​it is not possible in UD to mark the distinction between an element modifying the head of
the phrase and the same element modifying the whole phrase
\cite{doi:10.1146/annurev-linguistics-011718-011842}.

  One aspect of UD similar to UCCA is its preference of lexical (rather than functional) heads.
%  unlike other dependency schemes that prefer functional ones.
  For example, in auxiliary verb constructions (e.g., ``is eating''), UD
  marks the lexical verb (\textit{eating}) as the head, while other dependency schemes
  may select the auxiliary \textit{is} instead.
  While the approaches are largely inter-translatable
  \citep{Schwartz:12}, lexical head schemes are more similar in form to semantic schemes,
   such as UCCA and semantic dependencies \citep{oepen2016towards}.
%   This facilitates their comparison.
   
An example UD tree is given in Figure~\ref{fig:original_example_ud}.
%and Table~\ref{} gives a short description of each UD category.  % supp. material (footnote above)
UD relations will be written in \texttt{typewriter} font.

\begin{figure}[th]
  \centering
    \begin{dependency}[text only label, label style={above,font=\tt}, font=\small]
    \begin{deptext}[column sep=.8em,ampersand replacement=\^]
    After \^ graduation \^ , \^ John \^ moved \^ to \^ Paris \\
    \end{deptext}
        \depedge[edge unit distance=1ex]{2}{1}{case}
        \depedge[edge unit distance=1ex]{2}{3}{punct}
        \depedge[edge unit distance=1ex]{5}{4}{nsubj}
        \depedge[edge unit distance=1ex, edge end x offset=-2pt]{5}{2}{obl}
        \depedge[edge unit distance=1ex]{7}{6}{case}
        \deproot[edge unit distance=1.5ex]{5}{root}
        \depedge[edge unit distance=1.5ex]{5}{7}{obl}
    \end{dependency}
\caption{Example UD tree.\label{fig:original_example_ud}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Shared gold-standard Corpus}\label{sec:shared}

We annotate 163 English passages, containing 804 sentences
from the reviews section of the 
English Web Treebank \cite[EWT; ][]{bies2012english}.
Text is annotated by two UCCA annotators
according to v2.0 of the UCCA
guidelines\footnote{\scriptsize\url{github.com/UniversalConceptualCognitiveAnnotation/docs}}
and cross-reviewed.\footnote{\url{github.com/danielhers/UCCA_English-EWT}}
As these sentences are included in the UD
English\_EWT treebank, this is a \textit{shared} gold-standard UCCA and UD
annotated corpus.

The data contains 11,103 tokens---4\% of the full UD English\_EWT treebank,
and 20\% of its reviews section.
Of the UCCA-annotated sentences, 546 belong to the UD training set,
143 to the development set and 115 to the test set.
%\daniel{Add inter-annotator agreement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Comparison Methodology}\label{sec:methodology}

To facilitate comparison between UCCA and UD,
we first assimilate the graphs by abstracting away from formalism differences,
obtaining a similar graph format for both schemes.
We then match pairs of nodes in the converted UD and UCCA trees
if they share all terminals in their yields.

%One obvious difference is that
UD annotates bi-lexical dependency trees,
while UCCA graphs contain non-terminal nodes.
In \S\ref{sec:conversion}, we outline the unified DAG converter by
\citet{hershcovich2018multitask,hershcovich2018universal},\footnote{\url{github.com/huji-nlp/semstr}}
which we use to reach a common format.
In \S\ref{sec:local}, we describe a number of extensions
to the converter, which abstract away from further non-content differences.

\begin{figure}[th]
  \centering
  \scalebox{.8}{
  \begin{tikzpicture}[level distance=12mm, ->,
      every node/.append style={sloped,anchor=south,auto=false,font=\scriptsize\tt},
      level 2/.style={sibling distance=17mm,level distance=9mm},
      level 3/.style={sibling distance=12mm,level distance=14mm}]
    \tikzstyle{word} = [font=\rmfamily,color=black]
    \node [fill=black,circle] {}
      child {node (ROOT) [fill=black,circle] {}
      {
        child {node (after) [fill=black,circle] {}
        {
          child {node [word] {After{\color{white}g}\quad\quad} edge from parent node {case}}
          child {node [word] {\quad graduation\quad\quad} edge from parent node {head}}
        } edge from parent node {obl}}
        child {node {}
        {
          child {node [word] (comma) {\quad,{\color{white}g}} edge from parent [draw=none]}
        } edge from parent [draw=none]}
        child {node {}
        {
          child {node [word] (John) {John{\color{white}g}} edge from parent [draw=none]}
        } edge from parent [draw=none]}
        child {node {}
        {
          child {node [word] (moved) {moved{\color{white}g}} edge from parent [draw=none]}
        } edge from parent [draw=none]}
        child {node (to) [fill=black,circle] {}
        {
            child {node [word] {to{\color{white}g}} edge from parent node {case}}
            child {node [word] {Paris{\color{white}g}} edge from parent node {head}}
        } edge from parent node {obl}}
      } edge from parent node {head}}
      ;
      \draw (ROOT) to node {punct} (comma);
      \draw (ROOT) to node {nsubj} (John);
      \draw (ROOT) to node {head} (moved);
  \end{tikzpicture}}
\caption{Converted UD tree.
Intermediate non-terminals and \textit{head} edges are introduced by the unified DAG converter.
}\label{fig:converted_example_ud}
\end{figure}


\subsection{Basic Conversion}\label{sec:conversion}

Figure~\ref{fig:converted_example_ud} presents the same tree from Figure~\ref{fig:original_example_ud}
after conversion.
The converter adds pre-terminals per token,
and attaches them according to the original dependency tree:
traversing it from the root, for each head it creates a non-terminal
parent with the edge label {\it head}, and adds the dependents as children of 
the created non-terminal.
Relation subtypes are stripped,
leaving only universal relations.
For example, the language-specific definite article label
\texttt{det:def} is replaced by the universal \texttt{det}.

\paragraph{Reentrancies.}
Remote edges in UCCA enable reentrancy, forming a DAG together with primary edges.
UD allows reentrancy when including \textit{enhanced dependencies}\footnote{\url{universaldependencies.org/u/overview/enhanced-syntax.html}}
\cite{SCHUSTER16.779}, which form (bi-lexical) graphs, representing phenomena
such as predicate ellipsis (e.g., gapping),
and shared arguments due to coordination, control, raising and relative clauses.

UCCA is more inclusive in its use of remote edges, and accounts for 
the entire class of implicit arguments termed {\it Constructional Null Instantiation} in FrameNet \citep{Ruppenhofer:16}.
For example, in
``The Pentagon is bypassing official US intelligence channels [...] in order to create strife'' (from EWT),
remote edges mark \textit{Pentagon} as a shared argument of \textit{bypassing} and
\textit{create}. 
Another example is ``if you call for an appointment [...] so you can then make one'',
where a remote edge in UCCA indicates that \textit{one} refers to \textit{appointment}.
Neither is covered by enhanced UD.

In order to facilitate comparison, we remove remote edges and enhanced dependencies in the conversion process.
We thus compare basic UD and UCCA trees, deferring a comparison of UCCA and enhanced UD to future work.



\subsection{Extensions to the Converter}\label{sec:local}

We extend the unified DAG converter to remove further non-content differences.

\paragraph{Unanalyzable units.}
An unanalyzable phrase is represented in UCCA as a single unit covering multiple terminals.
In multi-word expressions (MWEs) in UD, each word after the first is attached to the previous word,
with the \texttt{flat}, \texttt{fixed} or \texttt{goeswith} relations
(depending on whether the expression is grammaticalized, or split by error).
We remove edges of these relations and group the corresponding terminals to one unit.
%Multi-word expressions also include compounds, discussed in \S\ref{sec:mwe}.

\paragraph{Promotion of conjunctions.}
The basic conversion generally preserves terminal yields:
the set of terminals spanned by a non-terminal is the same
as the original dependency yield of its head terminal
(e.g., in Figure~\ref{fig:converted_example_ud}, the yield of the non-terminal
headed by \textit{graduation} is ``After graduation'', the same as that of ``graduation''
in Figure~\ref{fig:original_example_ud}).

Since UD attaches subordinating and coordinating conjunctions to the following conjunct,
this results in them being positioned in the same conjunct they relate (e.g.,
\textit{After} will be included in the first conjunct in ``After arriving home, John went to sleep'';
\textit{and} will be included in the second conjunct in ``John and Mary'').
In contrast, UCCA places conjunctions as siblings to their conjuncts (e.g.,
``[After] [arriving home], [John went to sleep]'' and ``[John] [and] [Mary]''). 

To abstract away from these convention differences,
we place 
coordinating and subordinating conjunctions 
(i.e., \texttt{cc}-labeled units, and \texttt{mark}-labeled units with an \texttt{advcl} head such 
as \textit{when}, \textit{if}, \textit{after}) as siblings of their conjuncts.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analysis of Divergences}\label{sec:analysis}

Using the shared format,
we turn to analyzing the content differences between UCCA and UD.


\begin{table*}[t]
\centering
\setlength\tabcolsep{5pt}
\def\arraystretch{.855}
\begin{tabular}{lRRRRRRRRRRRRRRR}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{Participant (A)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Center (C)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{Adverbial (D)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Elaborator (E)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{Function (F)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Ground (G)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{ Parallel Scene (H)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Linker (L)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{Connector (N)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Process (P)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{Quantifier (Q)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Relator (R)}}
 & \multicolumn{1}{c}{\bf \rotatebox{90}{State (S)}} & \multicolumn{1}{c}{\bf \rotatebox{90}{Time (T)}}
 & \multicolumn{1}{c}{\rotatebox{90}{{\sc NoMatch}}} \\
\tt acl & 8 &&& 101 & 2 && 15 &&&&&& 1 && 49 \\
\tt advcl & 2 & 2 &&&&& 103 & 1 && 4 &&&&& 97 \\
\tt advmod & 61 & 9 & 399 & 51 & 12 & 33 & 3 & 61 && 2 & 10 & 6 & 5 & 117 & 71 \\
\tt amod & 1 & 33 & 99 & 197 & 2 && 7 &&& 3 & 27 && 97 & 2 & 60 \\
\tt appos & 1 & 10 && 8 &&& 5 &&&& 1 && 4 && 10 \\
\tt aux &&& 96 && 285 &&&&&&&&&& 2 \\
\tt case & 1 & 5 & 2 & 14 & 34 &&& 48 & 6 & 1 & 1 & 489 & 50 && 75 \\
\tt cc &&& 1 &&&&& 305 & 71 && 1 & 1 &&& 11 \\
\tt ccomp & 78 &&&&&& 8 &&&&&& 1 && 41 \\
\tt compound & 23 & 24 & 8 & 176 & 2 &&&&& 1 & 1 & 1 & 3 & 3 & 164 \\
\tt conj & 2 & 88 & 1 &&&& 265 &&& 2 &&& 3 && 90 \\
\tt cop &&&&& 333 &&&&& 3 && 1 & 24 && 3 \\
\tt csubj & 2 &&&&&&&&&&&&&& 8 \\
\tt dep &&&&&&&&&&&& 1 &&&\\
\tt det & 2 & 1 & 19 & 763 & 1 & 1 &&&&& 19 & 2 &&& 26 \\
\tt discourse && 1 &&& 1 & 6 & 13 & 3 &&&&& 1 && 1 \\
\tt expl &&&&& 22 &&&&&&&&&& 2 \\
\tt iobj & 19 &&&&&&&&&&&&&&\\
\tt list && 2 &&&&& 8 &&&&&&&& 2 \\
\tt mark && 2 & 3 && 186 & 1 && 134 & 1 &&& 53 & 1 & 1 & 18 \\
\tt nmod & 100 & 1 & 1 & 233 &&& 6 &&&&&& 3 & 4 & 110 \\
\tt nsubj & 993 &&&& 14 && 2 & 9 && 3 && 24 & 1 && 37 \\
\tt nummod & 4 & 7 && 6 &&& 3 &&&& 50 &&&& 24 \\
\tt obj & 439 & 7 & 5 & 1 & 1 && 1 & 1 && 8 & 1 & 6 && 4 & 92 \\
\tt obl & 247 & 1 & 21 & 7 & 2 & 4 & 4 & 4 &&& 3 & 2 && 69 & 132 \\
\tt orphan & 1 &&&&&&&&&&&&&& 1 \\
\tt parataxis & 1 &&& 1 && 2 & 79 &&& 1 &&& 2 && 39 \\
\tt vocative & 9 &&&&& 3 &&&&&&&&&\\
\tt xcomp & 44 & 1 & 2 & 2 &&& 1 &&& 5 &&& 7 && 116 \\
head & 125 & 1402 & 152 & 37 & 91 & 18 & 652 & 2 & 1 & 961 & 18 & 9 & 353 & 1 & 524 \\
\sc NoMatch & 329 & 172 & 34 & 56 & 6 & 5 & 466 & 29 && 141 & 27 & 7 & 98 & 11
\end{tabular}
\caption{UD-UCCA confusion matrix calculated from EWT
gold-standard annotations (\S\ref{sec:shared}),
after applying our extended converter to UD (\S\ref{sec:methodology}),
by matching UD vertices and UCCA units with the same terminal yield.
The last column (row), labeled {\sc NoMatch}, shows the number of edges of each UD (UCCA) category
that do not match any UCCA (UD) unit.
Zero counts are omitted.
\label{tab:confusion_matrix}}
\end{table*}

\subsection{Confusion Matrix}\label{sec:confusion}

Table~\ref{tab:confusion_matrix} presents the confusion matrix of categories between
the converted UD and UCCA, in the shared EWT corpus.
In case of multiple UCCA units with the same terminal yield (i.e., units with a single non-remote child),
we take the top category only, to avoid double-counting.
Excluding punctuation, this results in 12,893 yields in UCCA and
13,294 in UD.
Of these, 11,541 are common, meaning that a UCCA ``parser'' developed this way
would get a very high F1 score
of 88.1\%, if given the gold UCCA label for every converted edge.

Only 73\% of syntactic arguments
(\texttt{ccomp}, \texttt{csubj}, \texttt{iobj}, \texttt{nsubj}, \texttt{obj}, \texttt{obl} and \texttt{xcomp})
are Participants,
and only 73\% of Participants are syntactic arguments---a difference stemming from
the Scene/non-Scene (\S\ref{sec:s}) and argument/adjunct (\S\ref{sec:arguments}) distinctions.
%, this does not include the different treatment of shared arguments (\S\ref{sec:conversion}).
Moreover, if we identify predicates as words having at least one argument
and Scenes as units with at least one Participant,
then only 86\% of UD predicates correspond to Scenes (many of which are secondary relations within one scene; see \S\ref{sec:arguments}),
and only 79\% of Scenes correspond to predicates (e.g., due to eventive nouns).

Examining the {\it head} row in Table~\ref{tab:confusion_matrix} allows
us to contrast the schemes' notions of a head. 
{\it head}-labeled units cover units that have at least
one dependent in UD, or single-clause sentences (technically, they are non-terminals added by the converter).
77.5\% correspond to Processes, States, Parallel Scenes or Centers,
which are UCCA's notions of semantic heads.
12.1\% of the {\it head} units are left unmatched, mostly due to MWEs analyzed in
UD but not in UCCA (\S\ref{sec:mwe}).
Another source of unmatched units is inter-Scene linkage, which tends to be flatter in
UCCA (\S\ref{sec:linkage}).
The rest (10.4\%) are mostly due to head swap (e.g., ``\textit{all} of Dallas'', where \textit{all}
is a Quantifier of \textit{Dallas} in UCCA, but the head in UD).

In the following subsections, we review the main content differences between the schemes,
as reflected in the confusion matrix, and categorize them according to the UD relations
involved.

\subsection{Scenes vs. Non-Scenes}\label{sec:s}

UCCA distinguishes between Scenes and non-Scenes.
This distinction crosses UD categories,
as a Scene can be evoked by a verb, an eventive or stative
noun (\textit{negotiation}, \textit{fatigue}),
an adjective or even a preposition (``this is \textit{for} John'').

\paragraph{Core syntactic arguments.}
      Subjects and objects are usually Participants (e.g., ``\textit{wine} was excellent'').
      However, when describing a Scene, the subject may be a Process/State
      (e.g., ``but \textit{service} is very poor'').
      Some wh-pronouns are the subjects or objects of a relative clause, but
      are Linkers or Relators,
      depending on whether they link Scenes or non-Scenes, respectively.
      For example, ``who'' in ``overall, Joe is a happy camper \textit{who} has found a great spot'' is an \texttt{nsubj}, but a Linker.
      Other arguments are Adverbials or Time (see \S\ref{sec:arguments}), and
      some do not match any UCCA unit, especially when they are parts of MWEs (see \S\ref{sec:mwe}).

\paragraph{Adjectival modifiers} are Adverbials when modifying Scenes
    (``\textit{romantic} dinner''), States when describing non-Scenes (``\textit{beautiful} hotel'') 
    or when semantically predicative (``such a \textit{convenient} location''), or
    Elaborators where defining inherent properties of non-Scenes (``\textit{medical} school'').

\paragraph{Nominal and clausal modifiers.}
    Most are Participants or Elaborators,
    depending on whether they modify a Scene (e.g.,
    ``discount \textit{on services}'' and
    ``our decision \textit{to buy when we did}'' are Participants,
    but ``\textit{my car's} gears and brakes'' and ``Some of the younger kids \textit{that work there}'' are Elaborators).
    Unmatched \texttt{acl} are often
    free relative clauses (e.g., in ``the prices were worth what \textit{I got}'',
    \textit{what} is the \texttt{obj} of \textit{worth} but
    a Participant of \textit{I got}).

\paragraph{Case markers.}
      While mostly Relators
      modifying non-Scenes (e.g., ``the team \textit{at} Bradley Chevron''),
      some case markers are Linkers linking Scenes together 
      (e.g., ``very informative website \textit{with} a lot of good work'').
      Others are Elaborators (e.g., ``\textit{over} a year'') or States
      when used as the main relation in verbless or copula clauses
      (e.g., ``it is right \textit{on} Wisconsin Ave'').
    
\paragraph{Coordination.}
      Coordinating conjunctions (\texttt{cc}) are Connectors where they coordinate non-Scenes
      (e.g., ``Mercedes \textit{and} Dan'')
      or Linkers where they coordinate Scenes (e.g., ``outdated \textit{but} not bad'').
      Similarly, conjuncts and list elements (\texttt{conj}, \texttt{list}) may be Parallel Scenes (H),
      or Centers when they are non-Scenes.\footnote{While in UD 
      the conjunction \texttt{cc} is attached to the following conjunct,
      in UCCA coordination is a flat structure.
      This is a convention difference that we normalize (\S\ref{sec:local}).}

\paragraph{Determiners.}
      Articles are Elaborators, and so are determiners that modify non-Scenes 
      (e.g., ``I will never recommend this gym to \textit{any} woman'').
      However, where modifying Scenes (mostly negation)
      they are marked as Adverbials. For example, ``\textit{no} feathers in stock'', ``\textit{what} a mistake'',
      and ``the rear window had \textit{some} leakage'' are all Adverbials.



\subsection{Primary and Secondary Relations}\label{sec:arguments}

UD distinguishes core arguments, adverb modifiers,
and obliques, which in English UD mostly correspond to prepositional dependents of a verb.
UCCA distinguishes Participants, including locations and abstract entities,
from secondary relations (Adverbials), 
which cover manner, aspect and modality.
Adverbials can be verbs (e.g., \textit{begin}, \textit{fail}),
prepositional phrases (\textit{with disrespect}),
as well as modals, adjectives and adverbs.

\paragraph{Adverbs and obliques.}
    Most UD adverb modifiers are Adverbials (e.g., ``I \textit{sometimes} go''),
    but they may be Participants, mostly in the case of semantic arguments describing location (e.g., \textit{here}).
    Obliques
%   generally correspond in English to prepositional phrases, and
    may be
    Participants (e.g., ``wait \textit{for Nick}''), Time (e.g., ``for \textit{over 7 years}'') 
    or Adverbials---mostly manner adjuncts (\textit{by far}).

\paragraph{Clausal arguments}
    are Participant Scenes
    (e.g., ``it was great \textit{that they did not charge a service fee}'',
    ``did not really know \textit{what I wanted}'' or
    ``I asked them \textit{to change it}'').
    However, when serving as complements to a secondary verb, they
    will not match any unit in UCCA, as it places secondary verbs on the 
    same level as their primary relation. 
    For example, \textit{to pay} is an \texttt{xcomp} in ``they have to pay'', while
    the UCCA structure is flat: \textit{have to} is an Adverbial and \textit{pay} is a Process.
    Single-worded clausal arguments may correspond to a Process/State,
    as in ``this seems \textit{great}''.

\paragraph{Auxiliary verbs}
    are Functions (e.g., ``\textit{do} not forget''),
    or Adverbials when they are modals (e.g., ``you \textit{can} graduate''). Semi-modals 
    in UD are treated as clausal heads, which take a clausal complement. 
    For example, in ``able to do well'', UD treats \textit{able} as the head,
    which takes \textit{do well} as an \texttt{xcomp}. UCCA, on the other hand,
    treats it as an Adverbial, creating a mismatch for \texttt{xcomp}.
    

\subsection{Multi-Word Expressions}\label{sec:mwe}

UD and UCCA treat MWEs differently.
In UD they include names, compounds and grammaticalized fixed expressions.
UCCA treats names and grammaticalized MWEs as unanalyzable units,
but also a range of semantically opaque constructions
(e.g., light verbs and idioms).
On the other hand, compounds are not necessarily unanalyzable in UCCA,
especially if compositional.

\paragraph{Compounds.} English compounds are mostly nominal,
        and are a very heterogeneous category.
        Most compounds correspond to Elaborators (e.g., ``\textit{industry} standard''),
        or Elaborator Scenes (e.g., ``\textit{out-of-place} flat-screen TV''),
        and many are unanalyzable expressions (e.g., ``\textit{mark} up'').
        Where the head noun evokes a Scene, the dependent is often a Participant
        (e.g., ``\textit{food} craving''), but can also be an Adverbial 
        (e.g., ``\textit{first time} buyers'') depending on its semantic category.
        %In cases where t UCCA annotates both parts  may be a co-Center (e.g., ``\textit{sweet potato} tempura'').
        Other compounds in UD are phrasal verbs (e.g., ``figure \textit{out}'', ``cleaned \textit{up}''),
        which UCCA treats as unanalyzable (leading to unmatched units). 
            
\paragraph{Core arguments.}
      A significant number of subjects and objects are left unmatched as they
      form parts of MWEs marked in UCCA as unanalyzable. UD annotates
      MWEs involving a verb and its argument(s) just like any other clause, and therefore
      lacks this semantic content. Examples include light verbs (e.g., ``give {\it a try}''),
      idioms (``bites {\it the dust}''), and figures of speech (e.g., ``when \textit{it} comes to'', ``offer \textit{a taste} (of)''),
      all are UCCA units.
      
\paragraph{Complex prepositions.} Some complex prepositions (e.g., \textit{according to} or \textit{on top of}),
      not encoded as MWEs in UD, are unanalyzable in UCCA.


\subsection{Linkage}\label{sec:linkage}

\paragraph{Head selection.}
UCCA tends to flatten linkage, where UD, as a dependency scheme,
selects a head and dependent per relation.
This yields scope ambiguities for coordination, an inherently flat structure. 
For instance, ``unique gifts and cards'' is ambiguous in UD as to whether
\textit{unique} applies only to \textit{gifts} or to the whole phrase---both
annotated as in Figure~\ref{fig:conj_ud}.
UCCA, allowing non-terminal nodes, disambiguates this case (Figure~\ref{fig:conj_ucca}).

% For camera-ready: add this to the UCCA-annotated set
% 1	unique	unique	ADJ	JJ	Degree=Pos	2	amod	_	_
% 2	gifts	gift	NOUN	NNS	Number=Plur	0	root	_	_
% 3	and	and	CCONJ	CC	_	4	cc	_	_
% 4	cards	card	NOUN	NNS	Number=Plur	2	conj	_	_

\begin{figure}[th]
  \centering
\begin{subfigure}{.45\columnwidth}
    \begin{dependency}[text only label, label style={above,font=\tt}, font=\small, edge unit distance=1.5ex]
    \begin{deptext}[column sep=.1em,ampersand replacement=\^]
    unique \^ gifts \^ and \^ cards \\
    \end{deptext}
        \depedge{2}{1}{amod}
        \deproot{2}{root}
        \depedge{4}{3}{cc}
        \depedge{2}{4}{conj}
    \end{dependency}
    \caption{UD\label{fig:conj_ud}}
\end{subfigure}
\hfill
\begin{subfigure}{.45\columnwidth}
    \scalebox{.8}{
    \begin{tikzpicture}[level distance=9mm, sibling distance=14mm, ->,
        every circle node/.append style={fill=black}]
      \tikzstyle{word} = [font=\rmfamily,color=black]
      \node (ROOT) [circle] {}
        child {node [word] {unique} edge from parent node[left] {\scriptsize $E$}}
        child {node [circle] {}
        {
          child {node [word] {gifts} edge from parent node[left] {\scriptsize $C$}}
          child {node [word] {and} edge from parent node[left] {\scriptsize $N$}}
          child {node [word] {cards} edge from parent node[right] {\scriptsize $C$}}
        } edge from parent node[right] {\scriptsize $C$} }
        ;
    \end{tikzpicture}
    }
    \caption{UCCA\label{fig:conj_ucca}}
 \end{subfigure}
 \caption{Example for coordination in UD and UCCA.\label{fig:conj}}
\end{figure}


\paragraph{Clausal dependents.}
UD categorizes clause linkage into coordination,
subordination, argumenthood (complementation),
and parataxis. %(a residual category).
UCCA distinguishes argumenthood 
but conflates the others into the Parallel Scene category.
For example,
``We called few companies before \textit{we decided to hire them}''
and ``Check out The Willow Lounge, \textit{you'll be happy}'' are Parallel Scenes.

Note that while in UD, \texttt{mark} (e.g., \textit{before})
is attached to the dependent adverbial clause,
a UCCA Linker lies outside the linked Scenes.
To reduce unmatched \texttt{advcl} instances,
this convention difference is fixed by the converter
(\S\ref{sec:local}).
Many remaining unmatched units are due to conjunctions we could not reliably raise.
For instance, the marker \textit{to} introducing an \texttt{xcomp} is ambiguous between Linker
(purposive \textit{to}) and Function (infinitive marker).
Similarly, wh-pronouns may be Linkers
(``he was willing to budge a little on the price {\it which} means a lot to me''),
but have other uses in questions and free relative clauses.
Other mismatches result from the long tail of differences in how UD and UCCA construe linkage.
Consider the sentence in Figure~\ref{fig:linkage}.
While \textit{moment} is an oblique argument of \textit{know} in UD,
\textit{From the moment} is analyzed as a Linker in UCCA.

\begin{figure}[th]
\begin{subfigure}{\columnwidth}
  \begin{minipage}[c]{.12\textwidth}
    \caption{UD\label{fig:linkage_ud}}
  \end{minipage}
  \begin{minipage}[c]{.8\textwidth}
    \begin{dependency}[text only label, label style={above,font=\tt}, font=\small, edge unit distance=1.8ex]
    \begin{deptext}[column sep=.25em,ampersand replacement=\^]
    From \^ the \^ moment \^ you \^ enter \^ , \^ you \^ know \\
    \end{deptext}
        \depedge[edge unit distance=2.4ex]{3}{1}{case}
        \depedge{3}{2}{det}
        \depedge[edge unit distance=1ex]{8}{3}{obl}
        \depedge[edge unit distance=1.5ex]{3}{5}{acl}
        \depedge[edge start x offset=-5pt,edge unit distance=1ex]{5}{4}{nsubj}
        \depedge[edge unit distance=1.5ex]{8}{6}{punct}
        \depedge[edge start x offset=-10pt,edge unit distance=1ex]{8}{7}{nsubj}
        \deproot{8}{root}
    \end{dependency}
  \end{minipage}
\end{subfigure}

\begin{subfigure}{\columnwidth}
  \begin{minipage}[c]{.17\textwidth}
    \caption{UCCA\label{fig:linkage_ucca}}
  \end{minipage}
  \hspace{-8mm}
  \begin{minipage}[c]{.8\textwidth}
    \scalebox{.8}{
    \begin{tikzpicture}[level distance=9mm, sibling distance=28mm, ->,
        level 2/.style={sibling distance=9mm},
        every circle node/.append style={fill=black}]
      \tikzstyle{word} = [font=\rmfamily,color=black]
      \node (ROOT) [circle] {}
        child {node [circle] {}
        {
          child {node [word] {From} edge from parent node[left] {\scriptsize $R$}}
          child {node [word] {the} edge from parent node[left] {\scriptsize $E$}}
          child {node [word] {{\color{white}F}moment} edge from parent node[right] {\scriptsize $C$}}
        } edge from parent node[above] {\scriptsize $L$} }
        child {node [circle] {}
        {
          child {node [word] {you{\color{white}k}} edge from parent node[left] {\scriptsize $A$}}
          child {node [word] {{\color{white}y}enter} edge from parent node[right] {\scriptsize $P$}}
        } edge from parent node[left] {\scriptsize $H$} }
        child {node [circle] {}
        {
          child {node (comma) [word] {,} edge from parent [draw=none]}
          child {node [word] {you{\color{white}k}} edge from parent node[left] {\scriptsize $A$}}
          child {node [word] {{\color{white}y}know} edge from parent node[right] {\scriptsize $S$}}
        } edge from parent node[above] {\scriptsize $H$} }
        ;
      \draw[->] (ROOT) to node [right] {\scriptsize $U$} (comma);
    \end{tikzpicture}
    }
  \end{minipage}
 \end{subfigure}
 \caption{Example for clause linkage in UD and UCCA.\label{fig:linkage}}
\end{figure}
    

\subsection{Other Differences}\label{sec:misc}

\paragraph{Appositions}
    in UD always follow the modified noun,
    but named entities in them are UCCA Centers, regardless of position
    (e.g., in ``its sister store Peking Garden'', the UD head \textit{its sister store}
    is an Elaborator, while \textit{Peking Garden} is the Center).

\paragraph{Copulas.}
    UCCA distinguishes copular constructions expressing
    identity (e.g., ``This \textit{is} the original Ham's restaurant'') where the copula is annotated as State,
    and cases of attribution 
    (e.g., ``Mercedes and Dan \textit{are} very thorough'')
    or location (e.g., ``Excellent chefs \textit{are} in the kitchen''),
    where the copula is a Function.

\paragraph{Discourse markers and interjections.}
    Units relating a Scene to the speech event or to the speaker's opinion are Ground
    (e.g., ``\textit{no}, Warwick in New Jersey'' and ``\textit{Please} visit my website'').
    On the other hand, discourse elements that relate one Scene to another 
    are Linkers (e.g., \textit{anyway}).

\paragraph{Vocatives}
    are both Ground and Participants if they participate in the Scene \textit{and} are the party addressed.
    For example, \textit{Mark} in ``Thanks \textit{Mark}'' is both the person addressed and the one thanked.\footnote{UCCA allows marking more than one category over an edge, although this
    functionality is not used often for English.}
    
\paragraph{Expletives and subjects.}
    Expletives are generally Functions,
    but some instances of \textit{it} and \textit{that} are analyzed as \texttt{nsubj} in UD
    and as Function in UCCA (e.g., ``\textit{it}'s like driving a new car'').

\paragraph{Excluded relations.}
We exclude the following UD labels,
as they are irrelevant to our evaluation:
\texttt{root} (always matches the entire sentence);
\texttt{punct} (punctuation is not annotated in UCCA);
\texttt{dep} (unspecified dependency),
\texttt{orphan} (used for gapping, which is represented using remote edges in UCCA---see \S\ref{sec:conversion});
\texttt{fixed}, \texttt{flat} and \texttt{goeswith} (correspond to parts of unanalyzable units in UCCA,
    and so do not represent units on their own---see \S\ref{sec:local}).
%  \item[\texttt{clf}, \texttt{dislocated}, \texttt{reparandum}.] Not in EWT.




%\section{Improving UCCA Parsing with UD}\label{sec:silver}

%Syntactic dependency parsers require many training examples to achieve
%state-of-the-art results.
%Even after around 500K tokens, the learning curves do not seem to saturate
%\cite{de2017old,velldal2017joint}.
%
%Whereas the largest UCCA training set (English Wiki) contains 128K tokens,
%The largest joined English UD training set (EWT) contains 177K tokens.
%In French UCCA has just 10K training tokens whereas UD has 295K,
%and in German UCCA has 80K and UD 228K.
%
%\begin{table}[t]
%\centering
%\begin{tabular}{l|lll|lll}
%& \multicolumn{3}{c|}{\footnotesize \bf Primary} & \multicolumn{3}{c}{\footnotesize \bf Remote} \\
%& \footnotesize \textbf{LP} & \footnotesize \textbf{LR} & \footnotesize \textbf{LF}
%& \footnotesize \textbf{LP} & \footnotesize \textbf{LR} & \footnotesize \textbf{LF} \\
%\hline
%\footnotesize 10\% & 65.1 & 65.2 & 65.1 & 38.4 & 24.3 & 29.8\\
%\footnotesize 20\% & 68.9 & 68.3 & 68.6 & 47.1 & 28.0 & 35.2\\
%\footnotesize 30\% & 70.2 & 70.1 & 70.2 & 47.2 & 45.5 & 46.3\\
%\footnotesize 40\% & 71.5 & 71.3 & 71.4 & 52.5 & 46.1 & 49.1\\
%\footnotesize 50\% & 71.9 & 71.9 & 71.9 & 51.3 & 48.6 & 49.9\\
%\footnotesize 60\% & 71.3 & 72.4 & 71.9 & 52.9 & 45.5 & 48.9\\
%\footnotesize 70\% & 73.1 & 72.7 & 72.9 & 50.8 & 50.5 & 50.6\\
%\footnotesize 80\% & 73.5 & 72.6 & 73.0 & 52.8 & 47.0 & 49.8\\
%\footnotesize 90\% & 73.9 & 73.1 & 73.5 & 52.3 & 48.6 & 50.4\\
%\footnotesize 100\% & 74.7 & 74.8 & 74.8 & 48.5 & 51.2 & 49.8\\
%\end{tabular}
%\caption{
%Development scores for TUPA \protect\cite{hershcovich2017a} when trained on increasing amount of training data
%(English Wiki corpus).
%\label{tab:partial_data_results}}
%\end{table}
%
%Table~\ref{tab:partial_data_results} shows results for TUPA,
%trained on 10\%, 20\% etc. of the Wiki training set and tested on the Wiki development set.
%As can be seen, the primary labeled F1 continues improving substantially even from 90\% to 100\%
%of the training data. More training data is likely to yield even better performance.

\begin{table*}[ht]
\centering
\scriptsize
\setlength\tabcolsep{1.7pt}
\def\arraystretch{1.5}
\hspace{-2mm}
\begin{tabular}{cl|ccccccccccccccccccccccccccc}
&& \tt \rotatebox{90}{det} & \tt \rotatebox{90}{nsubj} & \tt \rotatebox{90}{aux} & \tt \rotatebox{90}{case} & \tt \rotatebox{90}{nummod} & \tt \rotatebox{90}{cop} & \tt \rotatebox{90}{iobj} & \tt \rotatebox{90}{advmod} & \tt \rotatebox{90}{mark} & \tt \rotatebox{90}{expl} & \tt \rotatebox{90}{obj} & \tt \rotatebox{90}{nmod} & \tt \rotatebox{90}{compound} & \tt \rotatebox{90}{cc} & \tt \rotatebox{90}{ccomp} & \tt \rotatebox{90}{obl} & \tt \rotatebox{90}{amod} & \tt \rotatebox{90}{acl} & \tt \rotatebox{90}{conj} & \tt \rotatebox{90}{advcl} & \tt \rotatebox{90}{xcomp} & \tt \rotatebox{90}{appos} & \tt \rotatebox{90}{vocative} & \tt \rotatebox{90}{parataxis} & \tt \rotatebox{90}{discourse} & \tt \rotatebox{90}{csubj} & \tt \rotatebox{90}{list} \\
\hline
\multirow{2}{*}{\footnotesize (a)}
& \bf Labeled F1 \% & 92 & 81 & 78 & 70 & 67 & 67 & 63 & 62 & 61 & 60 & 58 & 56 & 51 & 50 & 50 & 41 & 40 & 39 & 34 & 33 & 31 & 29 & 13 & 12 & 12 & 0 & 0 \\
& \bf Unlabeled F1 \% & 96 & 94 & 97 & 92 & 81 & 98 & 81 & 91 & 96 & 88 & 73 & 82 & 79 & 93 & 59 & 65 & 90 & 53 & 75 & 49 & 56 & 63 & 50 & 55 & 96 & 29 & 67 \\
\hline
\multirow{5}{*}{\footnotesize (b)}
& \bf Total in UD \# & 834 & 1083 & 383 & 727 & 94 & 364 & 19 & 840 & 400 & 24 & 566 & 458 & 406 & 400 & 128 & 496 & 528 & 176 & 451 & 209 & 178 & 39 & 12 & 125 & 26 & 10 & 12 \\
& \bf Match Gold \# & 808 & 1046 & 381 & 652 & 70 & 361 & 19 & 769 & 382 & 22 & 474 & 346 & 239 & 388 & 87 & 364 & 467 & 127 & 361 & 112 & 62 & 29 & 12 & 86 & 25 & 2 & 10 \\
& \bf Match Predicted \# & 778 & 959 & 363 & 680 & 61 & 354 & 13 & 697 & 375 & 21 & 335 & 303 & 238 & 358 & 61 & 234 & 435 & 70 & 265 & 51 & 60 & 19 & 4 & 45 & 25 & 5 & 5 \\
& \bf Labeled Correct \# & 728 & 815 & 291 & 465 & 44 & 239 & 10 & 454 & 230 & 13 & 233 & 181 & 122 & 187 & 37 & 122 & 180 & 38 & 106 & 27 & 19 & 7 & 1 & 8 & 3 & 0 & 0 \\
& \bf Unlabeled Correct \# & 759 & 941 & 361 & 616 & 53 & 351 & 13 & 670 & 363 & 19 & 296 & 266 & 188 & 347 & 44 & 194 & 408 & 52 & 234 & 40 & 34 & 15 & 4 & 36 & 24 & 1 & 5 \\
\hline
\multirow{3}{*}{\footnotesize (c)}
& \bf Labeled/Unlabeled \% & 96 & 87 & 81 & 75 & 83 & 68 & 77 & 68 & 63 & 68 & 79 & 68 & 65 & 54 & 84 & 63 & 44 & 73 & 45 & 68 & 56 & 47 & 25 & 22 & 13 & 0 & 0 \\
& \bf Majority Gold \% & 96 & 95 & 75 & 75 & 76 & 92 & 100 & 68 & 42 & 100 & 93 & 67 & 73 & 79 & 90 & 68 & 47 & 80 & 73 & 92 & 71 & 34 & 75 & 92 & 52 & 100 & 80 \\
& \bf Majority Train \% & 98 & 88 & 91 & 90 & 80 & 49 & 90 & 59 & 46 & 87 & 80 & 62 & 82 & 55 & 68 & 61 & 83 & 78 & 58 & 86 & 71 & 53 & 100 & 83 & 31 & 86 & 100 \\
\hline
\footnotesize (d)
& \bf Average Words \# & 1.0 & 1.6 & 1.0 & 1.0 & 1.2 & 1.0 & 1.1 & 1.2 & 1.0 & 1.0 & 3.1 & 2.4 & 1.2 & 1.0 & 7.4 & 3.8 & 1.2 & 5.1 & 5.3 & 6.0 & 5.8 & 2.9 & 1.6 & 5.7 & 1.0 & 3.3 & 2.0
\end{tabular}
\caption{Fine-grained evaluation of TUPA on EWT.
(a) Columns are sorted by labeled F1, measuring performance on each subset of edges.
Unlabeled F1 ignores edge categories, evaluating unit boundaries only.
(b) Instances of each UD relation;
of them, matching UCCA units in gold-standard and in TUPA's predictions;
their intersection, with/without regard to categories.
(c) 
Percentage of correctly categorized edges;
for comparison, percentage of most frequent category in gold (see~Table~\ref{tab:confusion_matrix})
and in the Wiki training set (by UDPipe-predicted dependencies).
(d) Average number of words in corresponding terminal yields.
%UD relations exclude
%\texttt{clf}, \texttt{dislocated}, \texttt{reparandum},
%\texttt{fixed}, \texttt{flat}, \texttt{goeswith},
%\texttt{dep}, \texttt{orphan}, and \texttt{root}.
%Of all UD relations, 89.5\%  match gold-standard UCCA units (see Table \ref{tab:confusion_matrix}).
\label{tab:fine_grained_results}}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Fine-Grained UCCA Evaluation}\label{sec:fine_grained}

In \S\ref{sec:analysis} we used our comparison methodology,
consisting of the conversion to a shared format and matching units by terminal yield,
to compare gold-standard UD and UCCA.
In this section we apply the same methodology to parser outputs,
using gold-standard UD for fine-grained evaluation.
%using both gold-standard and parsed UD for fine-grained evaluation.

\subsection{Experimental Setup}\label{sec:experiments}

%\begin{table}[t]
%\centering
%\small
%\setlength\tabcolsep{3.25pt}
%\begin{tabular}{l|ccc|ccc}
%& \multicolumn{3}{c|}{\footnotesize \bf {\#} tokens}
%& \multicolumn{3}{c}{\footnotesize \bf {\#} sentences} \\
%& \footnotesize \bf train & \footnotesize \bf dev & \footnotesize \bf test
%& \footnotesize \bf train & \footnotesize \bf dev & \footnotesize \bf test \\
%\hline
%%UCCA &&&&&&&&&&&&&&&&&\\
%\bf English EWT &&& 11,103 &&& 804 \\
%\bf English Wiki & 124,935 & 17,784 & & 4,113 & 514 \\
%%\bf English Wiki & 124,935 & 17,784 & 15,854 & 4,113 & 514 & 515 \\
%%Wiki 1.2.0 & 128444 & 14676 & 15313 & 4268 & 454 & 503 &&&&&&&&&&&\\
%%\bf English 20K &&& 12,574 &&& 492 \\
%%\bf French 20K & 618 & 6,374 & 5,962 & 15 & 238 & 239 \\
%%\bf German 20K & 119,872 & 12,334 & 12,325 & 5,211 & 651 & 652
%%\multicolumn{2}{l}{20K 1.0.0/0.9.0} && 12339 &&& 506 & 10047 & 1558 & 1324 & 413 & 67 & 67 & 79894 & 10059 & 42366 & 3429 & 561 & 2164 \\
%%\hline
%%UD 2.3 & \multicolumn{2}{l}{152141} && \multicolumn{2}{l}{12543} &&
%%\multicolumn{2}{l}{250658} && \multicolumn{2}{l}{14450} && \multicolumn{2}{l}{209131} && 13814 \\
%%\hline
%\end{tabular}
%\caption{Number of tokens and sentences in the training, development and test sets
%we use for each corpus.
%% and language.
%\label{tab:corpora}}
%\end{table}

\paragraph{Data.}

In addition to the UCCA EWT data (\S\ref{sec:shared}),
we use the UCCA English Wikipedia corpus v1.2.3 (Wiki),
%with the standard train/dev/test split.
%and the \textit{Twenty Thousand Leagues Under the Sea} corpora (\textit{20K}),
%annotated in English (v1.2.2), French (v1.2.2)
%and German (v1.0.1).\footnote{\url{github.com/UniversalConceptualCognitiveAnnotation}}
%As in previous work, we use English 20K only as an out-of-domain test set.
%For comparability with previous work \cite{hershcovich2017a,hershcovich2018multitask},
%we also perform our experiments on Wiki v1.2.0 \cite{abend2013universal},
%on 20K v1.0.0 in English and French \cite{sulem2015conceptual},
%and on 20K v0.9.0 in German.
%For UD, we use the English\_EWT, French\_GSD and German\_GSD
%treebanks from Universal Dependencies v2.3
%\cite{11234/1-2895}.\footnote{\url{hdl.handle.net/11234/1-2895}}
%These are the largest freely-available UD treebanks for these languages.
and the UD v2.3 English\_EWT treebank
\cite{11234/1-2895},\footnote{\url{hdl.handle.net/11234/1-2895}}
filtering it to get only the 804 sentences that were also annotated in UCCA.
We additionally use UDPipe v1.2 \cite{udpipe,udpipe:2017},
trained on
English\_EWT,\footnote{\url{hdl.handle.net/11234/1-2898}}
to parse Wiki to UD.
We apply the extended converter to UD as before (\S\ref{sec:local}).

\paragraph{Parser.}

We train a UCCA parser,
TUPA v1.3 \cite{hershcovich2017a,hershcovich2018multitask},
on Wiki, and evaluate it on EWT.
We evaluate this out-of-domain scenario as
we have both UCCA and UD gold-standard annotations for this test set.
By default, TUPA is trained and tested using syntactic features
predicted by spaCy.\footnote{\url{spacy.io}}
As using UDPipe in training and gold UD in testing yielded very similar
results, we only report the default setting.

%\paragraph{Evaluation of the comparison methodology.}
%
%To quantitatively assess our conversion protocol (\S\ref{sec:methodology}),
%we begin by applying it to
%the gold-standard UD trees of the English\_EWT shared sentences,
%and evaluate the \textit{unlabeled} precision, recall and F1 score
%with the gold-standard UCCA for the same sentences.
%We use standard UCCA evaluation, matching units by their terminal yields.
%%We then apply the label mapping to get fully labeled converted UCCA graphs.


\paragraph{Evaluation by gold-standard UD.}

UCCA evaluation is generally carried out by considering a predicted unit as correct if there
is a gold unit that matches it in terminal yield and labels. Precision, Recall and F-score (F1)
are computed accordingly.
For the fine-grained analysis, we split the gold-standard, predicted and matched UCCA units according
to the labels of the UD relations whose dependents have the same terminal yield (if any).

%evaluation of both gold-standard and predicted edges
%according to the UD relations they match by terminal yield
%(using our extended converter; .
%This allows error analysis of UCCA parsing according to syntactic phenomena.


%\paragraph{UCCA evaluation by automatically parsed UD.}
%
%To demonstrate the applicability of fine-grained analysis on UCCA data
%without gold-standard UD,
%we use UDPipe v1.2 \cite{udpipe,udpipe:2017}, trained on the UD v2.3 treebanks,
%to parse the Wiki and 20K test sets in English, French and German.
%We use the official UDPipe models trained on the English\_EWT, French\_GSD and German\_GSD
%treebanks, respectively\footnote{\url{hdl.handle.net/11234/1-2898}}.


%\paragraph{Baselines.}
%
%As a point of comparison, we evaluate TUPA \cite{hershcovich2017a} on the test sets,
%after training it on the UCCA training set for each language (Wiki for English,
%and 20K for French and German).
%For equal conditions,
%we train and test TUPA using features predicted by UDPipe,
%yielding slightly lower scores than previously reported using spaCy.%\footnote{\url{spacy.io}}

%\paragraph{Using converted UD as ``silver-standard'' data.}
%
%Using our conversion protocol (\S\ref{sec:conversion}),
%we convert the gold-standard UD graphs into UCCA.
%We use the converted UD data as ``silver-standard'' data \cite{W17-7306,N18-1104}
%and add it to the UCCA training set for training TUPA.

%\begin{table}[t]
%\centering
%\begin{tabular}{l|lll|lll}
%& \multicolumn{3}{c|}{\footnotesize \bf Primary} & \multicolumn{3}{c}{\footnotesize \bf Remote} \\
%& \footnotesize \textbf{UP} & \footnotesize \textbf{UR} & \footnotesize \textbf{UF}
%& \footnotesize \textbf{UP} & \footnotesize \textbf{UR} & \footnotesize \textbf{UF} \\
%\hline
%\multicolumn{4}{l|}{\small \bf English EWT (shared)} \\
%\footnotesize UD 2.3
%& 82.8 & 88.4 & 85.5 & 21 & 17.8 & 19.3 \\
%\footnotesize TUPA
%& 80.8 & 77.8 & 79.3 & 10.2 & 18.6 & 13.2 \\
%\multicolumn{4}{l|}{\small \bf English Wiki test} \\
%\footnotesize UDPipe
%& 76.7 & 81 & 78.8 & -- & -- & -- \\
%\footnotesize TUPA
%& 87.6 & 84.9 & 86.2 & 50.9 & 52.7 & 51.8 \\
%\multicolumn{4}{l|}{\small \bf English 20K} \\
%\footnotesize UDPipe
%& 79.9 & 84.7 & 82.3 & -- & -- & -- \\
%\footnotesize TUPA
%& 83.4 & 84.4 & 83.9 & 50.8 & 24 & 32.7 \\
%\multicolumn{4}{l|}{\small \bf French 20K test} \\
%\footnotesize UDPipe
%& 78.5 & 83.4 & 80.9 & -- & -- & -- \\
%\footnotesize TUPA
%& 72 & 72.5 & 72.2 & 21.9 & 3 & 5.3 \\
%\multicolumn{4}{l|}{\small \bf German 20K test} \\
%\footnotesize UDPipe
%& 81.5 & 85.3 & 83.4 & -- & -- & -- \\
%\footnotesize TUPA
%& 90.8 & 89.7 & 90.2 & 69.4 & 52.6 & 59.8
%\end{tabular}
%\caption{
%Unlabeled precision, recall and F1 (in~\%) for primary and remote edges.
%UD 2.3 is the gold-standard UD after conversion to the unified DAG format,
%and other rows correspond to automatically parsed UD after conversion (UDPipe)
%or directly parsed UCCA (TUPA).
%\label{tab:conversion_results_unlabeled}}
%\end{table}

\subsection{Results}\label{sec:results}

Table~\ref{tab:fine_grained_results} shows
fine-grained evaluation by UD relations.
%Out of the total number of dependencies in the UD trees for the shared sentences,
%we can see how many relations matched any gold-standard UCCA unit (\textit{Match gold}), and
%UCCA unit predicted by TUPA (\textit{Match pred.}).
%Out of the predicted UCCA units with a correct terminal yield (\textit{Unlabeled}),
%we can also see how many were given the correct category (\textit{Labeled}).
%For comparison, $\sfrac{\text{Mode}}{\text{Match gold}}\%$ measures how ``deterministic''
%the UCCA category is in the test EWT corpus, given the UD relation,
%and $\sfrac{\text{Train Mode}}{\text{Match}}\%$ in the training Wiki corpus.
%\textit{Mean {\#}Words} indicates how long units are on average.
TUPA does best on determiners, which are mostly one word Elaborators.
For nominal subjects,
TUPA correctly categorizes only 87\% of the correctly delineated units,
although 95\% of gold subjects are Participants.
This is possibly since their training set ratio is only 88\%,
suggesting domain adaptation techniques may be applicable.

Copulas, coordinating conjunctions and conjuncts
undergo similar distribution shift.
They are mostly Functions, Linkers and Parallel Scenes in EWT, respectively,
while the distribution in Wiki is less peaked, with more of the units annotated as
States, Connectors and Centers.
This is a distinction between identity and attribution for copulas,
and between Scenes/non-Scenes for coordination.

TUPA does relatively well on auxiliaries, numerical modifiers and markers,
despite the heterogeneous test distribution (Table~\ref{tab:confusion_matrix}),
possibly by making lexical distinctions
(e.g., modals and auxiliary verbs are both UD auxiliaries,
but are annotated as Adverbials and Functions, respectively).

The worst performance is on relatively rare relations,
which do not contribute much to the overall parser score.
However, inter-clause linkage, which TUPA also struggles with, is quite common.
Although the match between UCCA and UD is not perfect in these cases,
it is overall better than TUPA's unlabeled performance.
The same pattern recurs when using gold-standard syntax as features for TUPA.
TUPA is a transition-based parser, which uses UD parses as features. Our
results then suggest that encoding syntax more directly, perhaps using syntactic
scaffolding \citep{swayamdipta2018syntactic}
or guided attention \citep{strubell2018linguistically},
may assist in predicting unit boundaries.

Finally, TUPA often fails to make distinctions that are not encoded
in UD. For example, it does poorly on distinguishing between noun modifiers of
Scene-evoking nouns (Participants) and modifiers of other nouns (Elaborators),
obtaining roughly the same performance as 
a majority baseline based on the UD relation.
Lexical resources that distinguish eventive and relational nouns from concrete 
nouns may alleviate this problem.
In the similar case of compounds, lexical resources for light verbs and idioms may increase performance.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}\label{sec:discussion}

NLP tasks, such as paraphrasing, text simplification, machine translation, and question answering,
often require semantic distinctions that are difficult to extract from syntactic representations.

As a case in point, consider the example sentence
``after graduation, John moved to Paris'' again.
While the word \textit{graduation} evokes a Scene, as annotated in UCCA
(Figure~\ref{fig:example_ucca}), in UD it is an oblique modifier of \textit{moved},
just like \textit{Paris} is (Figure~\ref{fig:original_example_ud}).
The Scene/non-Scene distinction (\S\ref{sec:s})
would benefit structural text simplification systems,
which should preferably paraphrase the sentence to
``John graduated. (Then,) John moved to Paris'',
such that each Scene would occupy a single sentence \cite{sulem2018samsa}.

Another example is machine translation---translating the same sentence into Hebrew,
which does not have a word for \textit{graduation},
would require a clause to convey the same meaning.
The mapping would therefore be more direct using a semantic representation,
and we would benefit from breaking the utterance into two Scenes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}\label{sec:related_work}

The use of syntactic parsing as a proxy for semantic structure has a long tradition in NLP.
Indeed, semantic parsers have leveraged syntax
for output space pruning \cite{xue2004calibrating}, 
syntactic features \cite{gildea2002automatic,N15-1007,E17-1045}, 
joint modeling \cite{surdeanu2008conll,hajivc2009conll}, and
multi-task learning \cite{swayamdipta2016greedy,swayamdipta2018syntactic,strubell2018linguistically}.
Some syntactic representation approaches, notably CCG \cite{Steedman:00},
directly reflect the underlying semantics, and have been used to
transduce semantic forms using rule-based systems \cite{Basile:12}.

%Two CoNLL shared tasks on joint syntactic and semantic dependency parsing

%explored the connection between syntactic dependencies and
%semantic annotations built on top of them.
%Other works have contested the importance of syntax to semantics,
%by achieving strong performance without explicitly modeling syntax \cite{Peng-EtAl:2018:NAACL,P18-2077,P18-1192,C18-1233}.
  
However, empirical study of
the differences between syntactic and semantic schemes is still scarce.
\newcite{zhang2017evaluation} evaluated PredPatt \citep{white2016universal},
a framework for extracting predicate-argument structures from UD,
on a large set of converted PropBank annotations.
%They evaluated the extracted predicate-argument relations using both
%gold-standard and parsed UD.
\newcite{szubert2018structured} proposed a method for aligning AMR and UD subgraphs,
finding that 97\% of AMR edges are evoked by words or syntactic relations.
\newcite{damonte-17} refined AMR evaluation by UD labels.
Similarly, our conversion protocol allows fine-grained evaluation of UCCA parsing.

A related line of work tackles the transduction of syntactic structures into semantic ones.
\newcite{reddy2016transforming} proposed a rule-based method for converting UD
to logical forms. 
%They map syntactic dependency relations directly to logical relations,
%assuming the predicate-argument structure is isomorphic to the dependency structure,
%but handling exceptions by rules relating to specific linguistic constructions,
%namely prepositional phrases, conjunction, relatives clauses, and wh-questions.
\newcite{stanovsky2016getting} converted Stanford dependency trees into
proposition structures ({\sc PropS}), abstracting away from some syntactic detail.
% to achieve a more semantically-oriented representation.


\section{Conclusion}\label{sec:conclusion}

We evaluated the similarities and divergences in the content encoded by UD and UCCA. 
After annotating a portion of the English Web Treebank with UCCA,
  we used an automated methodology to evaluate how well the two schemes align,
  abstracting away from differences of mere convention.
We provided a detailed picture of the content differences between the schemes.
Notably, we quantified the differences between the notions of syntactic and semantic heads
  and arguments, finding substantial divergence between them.
Our findings highlight the potential utility of using semantic parsers for text understanding applications
  (over their syntactic counterparts), but also expose challenges semantic parsers must address,
  and potential sources for improvement.


%Finally, we demonstrated the utility of the proposed comparison methodology for fine-grained
%  evaluation of UCCA parsers, and exposed concrete paths for advancement in UCCA parsing.

%Future work will extend our conversion protocol to a full labeled conversion,
%which can be used as a UCCA parser, or for training data augmentation.

\section*{Acknowledgments}

This work was supported by the HUJI Cyber Security Research Center
in conjunction with the Israel National Cyber Bureau in the Prime Minister's Office.
We thank Jakob Prange, Nathan Schneider
and the anonymous reviewers for their helpful comments.


\bibliography{references}
\bibliographystyle{acl_natbib}

\end{document}
