%
% File naaclhlt2018.tex

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2018}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\title{Deep Multitask Learning for Transition-Based Semantic Parsing}

\author{Daniel Hershcovich$^{1,2}$ \\
  \\\And
  Omri Abend$^2$ \\
  $^1$The Edmond and Lily Safra Center for Brain Sciences \\
  $^2$School of Computer Science and Engineering \\
  Hebrew University of Jerusalem \\
  \texttt{\{danielh,oabend,arir\}@cs.huji.ac.il}
  \\\And
  Ari Rappoport$^2$
}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  Semantic representation schemes differ in many ways, but we show
  how they are similar and how this similarity can be exploited to
  improve parsing each of them.
\end{abstract}

\section{Introduction}\label{sec:introduction}

Following increased interest in semantic representation,
recent developments in natural language processing have focused on semantic parsing,
including frame-semantic parsing \cite{gildea2002automatic,swayamdipta2017frame,ringgaard2017sling},
Abstract Meaning Representation parsing \cite{damonte-17,11099},
Semantic Dependency Parsing \cite{P17-1186}, and
Universal Conceptual Cognitive Annotation parsing \cite{hershcovich2017a}, among others.
In parallel, Universal Dependency parsers \cite{dozat2016deep} are improving,
learning syntactic structure in a language-universal way.

While each of these representation schemes has its own set of distinctions it focuses on,
much of the semantic content is shared between many of them \cite{abend2017the}.
Given the success of multitask learning models in various tasks
\cite{luong2015multi,ruder2017overview}
including parsing specifically
\cite{Zhang2016StackpropagationIR,P17-1186,swayamdipta2017frame,guo2016exploiting}
and multilingual parsing \cite{TACL892},
we propose a multitask transition-based semantic parser.


\section{Tasks}\label{sec:tasks}

\subsection{Universal Conceptual Cognitive Annotation}\label{sec:ucca}

UCCA graphs are labeled, directed acyclic graphs (DAGs),
whose leaves correspond to the tokens of
the text. A node (or {\it unit}) corresponds to a terminal or
to several terminals (not necessarily contiguous) viewed as a
single entity according to semantic or cognitive considerations.
Edges bear a category, indicating the role of the sub-unit in the parent relation.

UCCA is a multi-layered representation, where each layer corresponds
to a ``module'' of semantic distinctions.
UCCA's \textit{foundational layer}, targeted in this paper, covers the predicate-argument
structure evoked by predicates of all grammatical categories
(verbal, nominal, adjectival and others), the inter-relations between them,
and other major linguistic phenomena such as coordination and multi-word expressions.
The layer's basic notion is the \textit{scene},
describing a state, action, movement or some other relation that evolves in time.
Each scene contains one main relation (marked as either a Process or a State),
as well as one or more Participants.
For example, the sentence ``After graduation, John moved to Paris''
contains two scenes, whose main relations are ``graduation'' and ``moved''.
``John'' is a Participant in both scenes, while ``Paris'' only in the latter.
Further categories account for inter-scene relations and the internal structure of
complex arguments and relations (e.g. coordination, multi-word expressions and modification).

One incoming edge for each non-root node is marked as \textit{primary},
and the rest (mostly used for implicit relations and arguments) as \textit{remote} edges,
a distinction made by the annotator.
The primary edges thus form a tree structure, whereas the remote edges enable reentrancy,
forming a DAG.

\subsection{Abstract Meaning Representation}\label{sec:amr}

Abstract Meaning Representation (AMR; \citet{banarescu2013abstract})
is a semantic representation for natural
language that embeds annotations related
to traditional tasks such as named entity
recognition, semantic role labeling, word
sense disambiguation and co-reference
resolution.

AMRs are rooted and directed
graphs with node and edge labels.
For most sentences in our dataset, the
AMR graph is a directed acyclic graph (DAG),
with a few specific cases where cycles are permitted.
These cases are rare, and for the purpose of
this paper, we consider AMR as DAGs.

\subsection{Semantic Dependency Parsing}\label{sec:sdp}

First defined in a SemEval 2014 shared task
\cite{oepen2014semeval}, and then extended by \citet{oepen2015semeval},
the broad-coverage semantic dependency parsing (SDP) task is centered around three
semantic formalisms whose annotations have been
converted into bilexical dependencies. The formalisms come
from varied linguistic traditions, but all three aim
to capture predicate-argument relations between
content-bearing words in a sentence.
While at first glance similar to syntactic dependencies,
semantic dependencies have distinct
goals and characteristics, more akin to semantic
role labeling (SRL; \citet{gildea2002automatic}) or
AMR. They abstract over different
syntactic realizations of the same or similar meaning
Conversely, they attempt to distinguish
between different senses even when realized
in similar syntactic forms.
Structurally, they are labeled directed graphs
whose vertices are tokens in the sentence. This
is in contrast to AMR whose vertices are abstract
concepts, with no explicit alignment to tokens,
which makes parsing more difficult \cite{flanigan2014discriminative}.
Their arc labels encode broadly-applicable semantic relations rather than being tailored
to any specific downstream application or
ontology.1 They are not necessarily trees, because
a token may be an argument of more than one
predicate. Their analyses may optionally leave out non–contentbearing
tokens, such as punctuation or the in-
finitival ``to,'' or prepositions that simply mark
the type of relation holding between other words.
But when restricted to content-bearing tokens (including
adjectives, adverbs, etc.), the subgraph
is connected. In this sense, SDP provides a
whole-sentence analysis. This is in contrast to
PropBank-style SRL, which gives an analysis of
only verbal and nominal predicates \cite{Palmer:05}.
Semantic dependency graphs also tend to
have higher levels of nonprojectivity than syntactic
trees \cite{oepen2014semeval}. Sentences with
graphs containing cycles have been removed from
the dataset by the organizers, so all remaining
graphs are directed acyclic graphs. Table 1 summarizes
some of the dataset’s high-level statistics.
Formalisms. Following the SemEval shared
tasks, we consider three formalisms. The
DM (DELPH-IN MRS) representation comes
from DeepBank \cite{flickinger2012deepbank}, which
are manually-corrected parses from the LinGO
English Resource Grammar \cite{copestake2000open}.
LinGO is a head-driven phrase
structure grammar (HPSG; \citet{pollard1994head})
with minimal recursion semantics \cite{copestake2005minimal}.
The PAS (Predicate-Argument Structures)
representation is extracted from the Enju
Treebank, which consists of automatic parses from
the Enju HPSG parser \cite{ninomiya2006extremely}.
In this work, we train and evaluate only on English annotations.
Of the three, PAS follows syntax most closely,
and prior work has found it the easiest to predict.

\subsection{Universal Dependencies}\label{sec:ud}

In recent years, the Universal Dependencies
(UD) representation \cite{nivre2016universal} has become
the dominant dependency representation for
annotating treebanks in a large variety of languages.
The goal of the UD project is to provide
guidelines for cross-linguistically consistent treebank
annotations for as many languages as possible.



\section{Transition-Based Universal Parser}\label{sec:model}

Similarly to \citet{hershcovich2017a}, we use a transition-based parser
with a general transition system that allows parsing any DAG structure.
To demonstrate its applicability, we apply the parser to the four datasets
in a single-task setting.



\section{Multitask Transition-Based Parsing}\label{sec:multitask}

Since the same model can be applied to different tasks, we also train it jointly on multiple tasks.
Rather than sharing the whole set of parameters (and getting a mix of action labels as a result),
we share only part of the model.
Specifically, in addition to the task-specific input-encoding bidirectional LSTM,
we use a shared bidirectional LSTM. The outputs of both LSTMs are concatenated and
fed into the task-specific MLP.
This is similar to \citet{P17-1186}.




\section{Experiments}\label{sec:experiments}

We perform various experiments to evaluate which of the representation schemes benefit each other.
As a baseline, we train the parser separately on each task.

\subsection{Data}\label{sec:data}

For UCCA, we use the English Wikipedia corpus \cite{abend2013universal},
and in addition, the English, French and German 20K corpus \cite{sulem2015conceptual}.
For AMR, we use LDC2016E25 used in SemEval 2016 \cite{may2017semeval}.
For SDP, we use SemEval 2015 \cite{oepen2015semeval}.
For UD, we use UD v2 used in CoNLL 2017 \cite{silveira14gold,zeman2017conll}.
Table~\ref{tab:corpora} shows the size of each corpus.

\begin{table}\label{tab:corpora}
\begin{tabular}{lcc}
Corpus & \# Tokens & \# Sentences \\
\textbf{UCCA} \\
Wiki & 158433 & 5225 \\
20K Leagues & 12339 & 506 \\
20K Leagues fr & 12929 & 547 \\
20K Leagues de & 113524 & 4764 \\
\textbf{UD} \\
English & 254850 & 16622 \\
French & 319253 & 16448 \\
German & 287110 & 15590 \\
\textbf{AMR} \\
LDC2016E25 &  & 39260 \\
bio &  & 6452 \\
\textbf{SDP} \\
SemEval 2015 & 802717 & 35657 \\
\end{tabular}
\caption{Size of each corpus.}
\end{table}

\subsection{Results}\label{sec:results}


\begin{table}\label{tab:single}
\begin{tabular}{lccc}
Parser \\
\textbf{UCCA} & Labeled Precision & Recall & F1 \\
\textbf{UD} & LAS F1 \\
\textbf{AMR} & Smatch Precision & Recall & F1 \\
\textbf{SDP} & Labeled Precision & Recall & F1 \\
\end{tabular}
\caption{Single-task results.}
\end{table}


\bibliography{references}
\bibliographystyle{acl_natbib}

\end{document}
